{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Classification - Network Traffic Analysis\n",
    "## Part 3 - MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we load the processed dataset file and use it to train several classification models.\n",
    "\n",
    "> **INPUT:** the ready dataset csv file as cleaned and processed in the previous phases.<br>\n",
    "> **OUTPUT:** a comparison of the prediction accuracy and performance of multiple machine learning classification algorithms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import precision_score, confusion_matrix, recall_score, accuracy_score, f1_score\n",
    "from statistics import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from joblib import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LOADING PROCESSED DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading dataset file into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize required variables to read the cleaned data file\n",
    "data_file_location = \"..\\\\data\\\\processed\\\\\"\n",
    "data_file_name = \"conn.log.labeled_processed\"\n",
    "data_file_ext = \".csv\"\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "data_df = pd.read_csv(data_file_location + data_file_name + data_file_ext, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring dataset summary and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23145, 31)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset shape\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id.orig_p</th>\n",
       "      <th>id.resp_p</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>label</th>\n",
       "      <th>proto_tcp</th>\n",
       "      <th>proto_udp</th>\n",
       "      <th>service_dhcp</th>\n",
       "      <th>service_dns</th>\n",
       "      <th>service_http</th>\n",
       "      <th>service_irc</th>\n",
       "      <th>conn_state_OTH</th>\n",
       "      <th>conn_state_RSTR</th>\n",
       "      <th>conn_state_S0</th>\n",
       "      <th>conn_state_S1</th>\n",
       "      <th>conn_state_S3</th>\n",
       "      <th>conn_state_SF</th>\n",
       "      <th>history_C</th>\n",
       "      <th>history_D</th>\n",
       "      <th>history_Dd</th>\n",
       "      <th>history_Other</th>\n",
       "      <th>history_S</th>\n",
       "      <th>history_ShAdDaf</th>\n",
       "      <th>history_ShAdDaft</th>\n",
       "      <th>history_ShAdfDr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.628686</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.620050</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>2.366458e-06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.628686</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.620022</td>\n",
       "      <td>3.097425e-07</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>7.888192e-07</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628686</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.620022</td>\n",
       "      <td>3.097425e-07</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>7.888192e-07</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.628686</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.221583</td>\n",
       "      <td>1.972292e-06</td>\n",
       "      <td>0.780758</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>7.263710e-05</td>\n",
       "      <td>0.08972</td>\n",
       "      <td>0.823184</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.628717</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.621946</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>2.366458e-06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id.orig_p  id.resp_p  duration    orig_bytes  resp_bytes  missed_bytes  \\\n",
       "0   0.628686   0.001238  0.620050  0.000000e+00    0.000000           0.0   \n",
       "1   0.628686   0.001238  0.620022  3.097425e-07    0.000047           0.0   \n",
       "2   0.628686   0.001238  0.620022  3.097425e-07    0.000047           0.0   \n",
       "3   0.628686   0.001238  0.221583  1.972292e-06    0.780758           0.5   \n",
       "4   0.628717   0.001238  0.621946  0.000000e+00    0.000000           0.0   \n",
       "\n",
       "   orig_pkts  orig_ip_bytes  resp_pkts  resp_ip_bytes  label  proto_tcp  \\\n",
       "0   0.000163   2.366458e-06    0.00000       0.000000      0        1.0   \n",
       "1   0.000054   7.888192e-07    0.00000       0.000000      0        1.0   \n",
       "2   0.000054   7.888192e-07    0.00000       0.000000      0        1.0   \n",
       "3   0.005097   7.263710e-05    0.08972       0.823184      0        1.0   \n",
       "4   0.000163   2.366458e-06    0.00000       0.000000      0        1.0   \n",
       "\n",
       "   proto_udp  service_dhcp  service_dns  service_http  service_irc  \\\n",
       "0        0.0           0.0          1.0           0.0          0.0   \n",
       "1        0.0           0.0          1.0           0.0          0.0   \n",
       "2        0.0           0.0          1.0           0.0          0.0   \n",
       "3        0.0           0.0          0.0           1.0          0.0   \n",
       "4        0.0           0.0          1.0           0.0          0.0   \n",
       "\n",
       "   conn_state_OTH  conn_state_RSTR  conn_state_S0  conn_state_S1  \\\n",
       "0             0.0              0.0            1.0            0.0   \n",
       "1             0.0              0.0            1.0            0.0   \n",
       "2             0.0              0.0            1.0            0.0   \n",
       "3             0.0              0.0            0.0            0.0   \n",
       "4             0.0              0.0            1.0            0.0   \n",
       "\n",
       "   conn_state_S3  conn_state_SF  history_C  history_D  history_Dd  \\\n",
       "0            0.0            0.0        0.0        0.0         0.0   \n",
       "1            0.0            0.0        0.0        0.0         0.0   \n",
       "2            0.0            0.0        0.0        0.0         0.0   \n",
       "3            0.0            1.0        0.0        0.0         0.0   \n",
       "4            0.0            0.0        0.0        0.0         0.0   \n",
       "\n",
       "   history_Other  history_S  history_ShAdDaf  history_ShAdDaft  \\\n",
       "0            0.0        1.0              0.0               0.0   \n",
       "1            0.0        1.0              0.0               0.0   \n",
       "2            0.0        1.0              0.0               0.0   \n",
       "3            1.0        0.0              0.0               0.0   \n",
       "4            0.0        1.0              0.0               0.0   \n",
       "\n",
       "   history_ShAdfDr  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset head\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into independent and dependent variables\n",
    "data_X = data_df.drop(\"label\", axis=1)\n",
    "data_y = data_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the performance of several models, we choose a set of the most popular machine learning algorithms for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classification models\n",
    "classifiers = [\n",
    "    # Since we have unbalanced labels, we use the Complement version of Naive Bayes which is particularly suited for imbalanced data sets.\n",
    "    (\"Naive Bayes\", ComplementNB()),\n",
    "    \n",
    "    # We use the Decision Tree with its default parameters, including the \"Gini Impurity\" to measure the quality of splits and ccp_alpha=0 (no pruning is performed). \n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    \n",
    "    # Logistic Regression model to help discovering linearity separation in the data set.\n",
    "    (\"Logistic Regression\", LogisticRegression()),\n",
    "    \n",
    "    # The efficient Random Forest model with a default base estimators of 100.\n",
    "    (\"Random Forest\", RandomForestClassifier()),\n",
    "    \n",
    "    # The classifier version of Support Vector Machine model.\n",
    "    (\"Support Vector Classifier\", SVC()),\n",
    "    \n",
    "    # The distance-based KNN classifier with a default n_neighbors=5.\n",
    "    (\"K-Nearest Neighbors\", KNeighborsClassifier()),\n",
    "  \n",
    "    # The most powerful ensemble model of XGBoost with some initially tuned hyperparameters.\n",
    "    (\"XGBoost\", xgb.XGBClassifier(objective = \"binary:logistic\", alpha = 10)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the cross-validation technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to obtain better representative results of the performance of each model across several iterations, we use cross-validation instead of the regular train/test split.\n",
    "- Since we are dealing with imbalanced class distributions, we implement a Stratified K-Folds cross-validator instead of the random KFold sampling. This is useful to preserve the percentage of both labels in each fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the cross-validator with 5 splits and sample shuffling activated\n",
    "skf_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Started!\n",
      "### [Naive Bayes]: Processing ...\n",
      "### [Decision Tree]: Processing ...\n",
      "### [Logistic Regression]: Processing ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [Random Forest]: Processing ...\n",
      "### [Support Vector Classifier]: Processing ...\n",
      "### [K-Nearest Neighbors]: Processing ...\n",
      "### [XGBoost]: Processing ...\n",
      "Model Training Finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Training Started!\")\n",
    "# Initialize the results summary\n",
    "classification_results = pd.DataFrame(index=[c[0] for c in classifiers], columns=[\"Accuracy\", \"TN\", \"FP\", \"FN\", \"TP\", \"Recall\", \"Precision\", \"F1\"])\n",
    "\n",
    "# Iterate over the estimators\n",
    "for est_name, est_object in classifiers:\n",
    "    \n",
    "    print(f\"### [{est_name}]: Processing ...\")\n",
    "    \n",
    "    # Initialize the results for each classifier\n",
    "    accuracy_scores = []\n",
    "    confusion_matrices = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    # Initialize best model object to be saved\n",
    "    models_path = \"..\\\\models\"\n",
    "    best_model = None\n",
    "    best_f1 = -1\n",
    "    \n",
    "    # Iterate over the obtained folds\n",
    "    for train_index, test_index in skf_cv.split(data_X, data_y):\n",
    "\n",
    "        # Get train and test samples from the cross-validation model\n",
    "        X_train, X_test = data_X.iloc[train_index], data_X.iloc[test_index]\n",
    "        y_train, y_test = data_y.iloc[train_index], data_y.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        est_object.fit(X_train.values, y_train.values)\n",
    "        \n",
    "        # Predict the test samples\n",
    "        y_pred = est_object.predict(X_test.values)\n",
    "        \n",
    "        # Calculate and register accuracy metrics\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        confusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        est_f1_score = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(est_f1_score)\n",
    "        \n",
    "        # Compare with best performing model\n",
    "        if best_f1 < est_f1_score:\n",
    "            best_model = est_object\n",
    "            best_f1 = est_f1_score\n",
    "    \n",
    "    # Summarize the results for all folds for each classifier\n",
    "    tn, fp, fn, tp = sum(confusion_matrices).ravel()\n",
    "    classification_results.loc[est_name] = [mean(accuracy_scores),tn,fp,fn,tp,mean(recall_scores),mean(precision_scores),mean(f1_scores)]\n",
    "    \n",
    "    # Save the best performing model\n",
    "    if best_model:\n",
    "        model_name = est_name.replace(' ', '_').replace('-', '_').lower()\n",
    "        model_file = model_name + \".pkl\"\n",
    "        dump(best_model, models_path + \"\\\\\" + model_file)\n",
    "    \n",
    "print(\"Model Training Finished!\")   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.994772</td>\n",
       "      <td>1838</td>\n",
       "      <td>85</td>\n",
       "      <td>36</td>\n",
       "      <td>21186</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.997152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.999914</td>\n",
       "      <td>1923</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21220</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.994772</td>\n",
       "      <td>1830</td>\n",
       "      <td>93</td>\n",
       "      <td>28</td>\n",
       "      <td>21194</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>0.995631</td>\n",
       "      <td>0.997154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.999827</td>\n",
       "      <td>1923</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21218</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <td>0.995636</td>\n",
       "      <td>1824</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>21220</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.995356</td>\n",
       "      <td>0.997626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.99771</td>\n",
       "      <td>1880</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>21212</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.997977</td>\n",
       "      <td>0.998752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.999914</td>\n",
       "      <td>1923</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21220</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy    TN  FP  FN     TP    Recall Precision  \\\n",
       "Naive Bayes                0.994772  1838  85  36  21186  0.998304  0.996004   \n",
       "Decision Tree              0.999914  1923   0   2  21220  0.999906       1.0   \n",
       "Logistic Regression        0.994772  1830  93  28  21194  0.998681  0.995631   \n",
       "Random Forest              0.999827  1923   0   4  21218  0.999812       1.0   \n",
       "Support Vector Classifier  0.995636  1824  99   2  21220  0.999906  0.995356   \n",
       "K-Nearest Neighbors         0.99771  1880  43  10  21212  0.999529  0.997977   \n",
       "XGBoost                    0.999914  1923   0   2  21220  0.999906       1.0   \n",
       "\n",
       "                                 F1  \n",
       "Naive Bayes                0.997152  \n",
       "Decision Tree              0.999953  \n",
       "Logistic Regression        0.997154  \n",
       "Random Forest              0.999906  \n",
       "Support Vector Classifier  0.997626  \n",
       "K-Nearest Neighbors        0.998752  \n",
       "XGBoost                    0.999953  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. RESULT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, all the models are performing very well with very high accuracy, precision, recall, and F1 scores. The Decision Tree, Random Forest, and XGBoost models are achieving near-perfect performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models evaluation:*\n",
    "- **Naive Bayes** achieved relatively good overall accuracy although the labels are not evenly distributed. \n",
    "- **Decision Tree** delivered one of the highest prediction accuracies, benefiting from its algorithmic resilience to imbalanced labels.\n",
    "- **Logistic Regression** also achieved good results, though it yielded a higher number of incorrect predictions, suggesting some linearity in the dataset.\n",
    "- **Random Forest** as anticipated, demonstrated superior performance as one of the most efficient prediction methods. However, given the strong performance of the Decision Tree, there was no significant improvement noticed when using Random Forest.\n",
    "- **Support Vector Classifier** also produced relatively good results with slightly higher False Positive rates.\n",
    "- **KNN** model likewise performed well, with a minimal number of incorrect predictions, which can be attributed to the dataset's normalization between 0 and 1.\n",
    "- **XGBoost** was expectedly among the best estimators since it's arguably the most powerful machine learning algorithm these days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Overall observations:*\n",
    "- Remarkably accurate predictions were generated by most models, considering that the numbers of False Positives/Negatives are cumulative results from five separate iterations.\n",
    "- Out of the seven estimators, four achieved relatively lower accuracy, but these could potentially be improved with further model tuning.\n",
    "- Regardless of the model used, there were consistently some False Negative predictions, which might be attributed to anomalies or outliers in the original dataset.\n",
    "- Lower accuracy models tend to produce errors primarily in the form of False Positives, largely because the majority of the population is labeled as \"Malicious\".\n",
    "- Based on their performance, models can be categorized into two distinct groups with quite similar behavior: one group exhibits significantly high accuracy, including DT, RF, and XGB, while the second group shows relatively good performance, comprising NB, KNN, LogR, and SVC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
